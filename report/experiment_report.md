# 项目实验报告

## 项目概述
本项目旨在使用机器学习方法预测SQL查询的实际返回行数（基数估计）。准确的基数估计对于数据库查询优化器选择最高效的执行计划至关重要，错误的估计可能导致数量级的性能差异。传统方法依赖启发式和统计信息，而本项目探索了数据驱动的ML方法来提升预测精度。

## 数据处理与特征工程回顾
整个数据流水线被设计为模块化、可迭代的脚本，以便于实验和改进。

### 1. 初始数据处理 (`1_preprocess_data.py`)
此阶段为后续分析和模型训练奠定了基础。
- 解析了原始JSON数据中的`explain_result`，这是获取数据库内部执行计划信息的关键。
- 关键步骤：递归移除了训练数据中所有以 "Actual" 开头的字段。这是为了防止信息泄露，因为这些字段（如 "Actual Rows", "Actual Startup Time"）直接揭示了查询的真实性能，包含了目标变量或与其高度相关的信息。在测试集中这些字段是不可用的。
- 为训练集提取了`target_actual_rows`作为监督学习的目标。
- 输出为JSONL格式 (`train_processed.jsonl`, `test_processed.jsonl`)，便于后续流式处理大规模数据。

### 2. 查询转换与基础特征 (`2_transform_queries.py`)
此脚本将SQL查询文本和原始执行计划转换为结构化的特征表示。
- **SQL解析 (`SQLParser`)**: 
    - 细致地从SQL查询字符串中提取了表名、表别名、JOIN条件（包括连接的表和列）以及过滤条件（表、列、操作符和值）。
    - 正确处理表别名对于理解复杂查询中哪些表实际参与了操作至关重要。
- **基础特征提取 (`FeatureExtractor`)**: 
    - 生成了第一批核心特征，包括：
        - **结构性特征**: 查询涉及的表数量、JOIN数量、过滤条件数量。
        - **表存在特征**: 基于预定义映射（`title`:0, `movie_companies`:1, etc.）的One-hot编码向量，指示查询中出现了哪些表。
        - **初步计划特征**: 直接从数据库提供的执行计划中提取的预估值，如总成本 (`total_cost`)、启动成本 (`startup_cost`)、计划行数 (`plan_rows`) 和计划宽度 (`plan_width`)。这些是数据库优化器自身对查询的评估。
        - **计划节点类型**: 统计了执行计划中不同节点类型（如 Hash Join, Seq Scan, Index Scan）的出现次数，以捕捉计划结构的特征。
- 输出为 `train_transformed.jsonl` 和 `test_transformed.jsonl`，其中每个查询都附带了其解析后的结构和提取的特征集。

### 3. 探索性数据分析 (`3_analyze_transformed_data.py` - 成果总结)
在进行更复杂的特征工程之前，对转换后的数据进行了深入分析 (此分析脚本的结果指导了后续步骤，其主要发现已整合入特征工程的决策中)：
- **统计分析**: 检查了查询数量、表的使用频率、JOIN和过滤条件的分布、最常见的表组合模式等。
- **关键洞察**: 分析揭示了训练集和测试集在查询复杂度（如最大JOIN数、最大表数量）和特定表组合模式上存在差异。例如，测试集包含比训练集更复杂的JOIN（最多4个JOIN vs 训练集最多2个）和更多表的查询。这一发现直接推动了后续V3鲁棒性特征的设计。

### 4. 高级特征工程 V2 (`9_analyze_table_column_usage.py`, `10_prepare_features_v2.py`)
此阶段的目标是创建更细粒度、更具表达力的特征。
- **共享结构分析 (`9_analyze_table_column_usage.py`)**: 
    - 一个关键的发现是：尽管查询实例不同，训练集和测试集使用了完全相同的表集合、列集合、表-列对偶、过滤模式（表-列-操作符组合）和JOIN模式（连接的表-列对偶组合）。
    - 这些共享的结构元素被提取并保存到 `feature_mapping.json` 中，为后续一致的特征编码提供了基础。
- **扩展特征集 (`AdvancedFeatureEncoder` V2 in `10_prepare_features_v2.py`)**: 
    - 利用 `feature_mapping.json`，将基础的36个特征扩展到了78个。
    - **新增特征类别包括**: 
        - **One-hot编码的表-列使用情况**: 针对 `feature_mapping.json` 中的每个唯一表-列对，如果其在查询的过滤或JOIN条件中被使用，则对应特征为1。
        - **特定过滤模式计数**: 对每个唯一的（表, 列, 操作符）过滤模式，统计其在查询中出现的次数。
        - **特定JOIN模式计数**: 对每个唯一的JOIN连接对（排序以保证一致性），统计其出现次数。
        - **表级统计**: 对每个表，统计其参与的过滤条件数量和JOIN操作数量。
        - **过滤值数值特征**: 提取过滤条件中的数值型值，计算其（对数转换后的）最小、最大、平均值以及数值型过滤条件的数量。
- 输出为处理后的Numpy数组 (`X_train_v2.npy`, `y_train_v2.npy`, `X_test_v2.npy`) 和包含特征名等元数据的 `metadata_v2.pkl`。这一步显著提升了模型的性能。

### 5. 鲁棒性特征工程 V3 (`10_prepare_features_v3.py`)
针对在`3_analyze_transformed_data.py`中观察到的训练集与测试集之间的复杂度差异，以及为了提升模型在未见过的高复杂度查询上的泛化能力，设计了V3特征。
- **`AdvancedFeatureEncoderV3`** 在V2的78个特征基础上，进一步增加了8个旨在捕捉查询复杂度并提高模型鲁棒性的特征，总数达到86个：
    - `exceeds_train_max_joins`: 布尔特征，指示查询的JOIN数量是否超过训练集中观察到的最大JOIN数 (即 > 2)。
    - `exceeds_train_max_tables`: 布尔特征，指示查询的表数量是否超过训练集中观察到的最大表数 (即 > 3)。
    - `tables_X_joins`: 表数量与JOIN数量的简单交互项 (`num_tables * num_joins`)，用于捕捉两者结合的复杂度。
    - `num_distinct_tables_in_joins`: JOIN操作中涉及的唯一表名的数量，反映JOIN操作的广度。
    - `filter_equality_ratio`: 等式过滤条件（如 `col = val`）占总过滤条件的比例，衡量查询选择的精确性。
    - `filter_range_ratio`: 范围过滤条件（如 `col > val`, `col < val`）占总过滤条件的比例。
    - `has_filter_on_title_pyear`: 布尔特征，指示查询是否对 `title.production_year` 列进行了过滤。
    - `has_filter_on_title_kind_id`: 布尔特征，指示查询是否对 `title.kind_id` 列进行了过滤。这些特定列的过滤在数据集中可能比较常见或重要。
- 输出与V2类似，但文件名和元数据对应V3版本 (`X_train_v3.npy`, etc.)。

## 模型迭代与评估
所有模型均使用**MSLE (Mean Squared Logarithmic Error)** 作为主要评估指标。MSLE特别适合目标值跨越多个数量级（如行数估计）的回归问题，因为它惩罚相对误差而非绝对误差。目标变量（实际行数）在送入模型训练前均通过 `np.log1p` 进行变换，以稳定方差并使分布更接近正态；模型预测出的对数值再通过 `np.expm1` 进行逆变换得到最终的行数估计。训练数据按80/20的比例划分为训练集和验证集进行模型选择和调优。

**重要说明**: 本报告中列出的所有MSLE损失值，均是基于本地从训练集中划分出的验证集（20%的训练数据）得到的结果。这些结果并非在竞赛官方的隐藏测试集上评估后，通过竞赛服务器返回的最终得分。本地验证集与官方测试集之间可能存在数据分布上的差异（例如，查询结构、选择的列——如训练集中多为 `SELECT a, b, c FROM ...` 而官方测试集可能包含更多 `SELECT * FROM ...` 的情况、数据稀疏性等），这些差异可能导致本地验证性能与竞赛服务器上的实际性能存在偏差。

## 模型比较
下表总结了不同模型在本地验证集上的MSLE表现以及其他相关信息：

| 模型                     | 特征数量 | 验证集 MSLE | 训练集 MSLE | 备注                       |
|--------------------------|----------|-------------|-------------|----------------------------|
| XGBoost V3 (Robust Features) | 86       | 0.766269    | 0.398373    | 鲁棒特征 (86)                  |
| XGBoost V2 (Advanced Features) | 78       | 0.774980    | 0.385781    | 高级特征 (78)                  |
| XGBoost V1 (Basic Features) | 36       | 1.396434    | 1.094386    | 基础特征 (36)                  |
| Random Forest            | 36       | 1.427542    | 1.199765    | 基础特征 (36)                  |
| Baseline (Plan Rows)     | 1        | N/A         | 2.410165    | 使用执行计划行数作为预测               |


# 项目最终总结与模型推荐

## 模型性能详细回顾
经过一系列的特征工程和模型迭代，各个模型在本地验证集上表现如下：

### 1. Baseline (Plan Rows)
- **描述**: 此模型直接使用数据库查询优化器提供的预估行数 (`plan_rows` 从执行计划中提取) 作为预测值。这代表了不使用额外ML模型的基准性能。
- **特征数量**: 1 (仅 `plan_rows`)
- **训练集 MSLE**: 2.410165
- **本地验证集 MSLE**: N/A (此模型不进行训练，直接在训练集上评估以与后续模型对比)
- **观察**: MSLE较高，表明仅依赖数据库自身估计存在较大误差空间，为ML模型提供了改进机会。

### 2. Random Forest
- **描述**: 采用V1基础特征集（36个特征）训练了一个标准的随机森林回归器，作为首个尝试的机器学习模型。
- **特征数量**: 36
- **训练集 MSLE**: 1.199765
- **本地验证集 MSLE**: 1.427542
- **训练时间**: 0.35 秒
- **观察**: 相比基线有显著提升，证明了机器学习方法在此问题上的潜力。验证集性能略逊于训练集，提示可能存在轻微过拟合或特征表达能力不足。

### 3. XGBoost V1 (Basic Features)
- **描述**: 使用与随机森林相同的V1基础特征集（36个特征）训练了XGBoost模型。XGBoost因其在结构化数据上的强大性能和效率而被选择。
- **特征数量**: 36
- **训练集 MSLE**: 1.094386
- **本地验证集 MSLE**: 1.396434
- **训练时间**: 0.40 秒
- **最佳迭代**: 133
- **观察**: XGBoost V1表现略优于随机森林，本地验证MSLE从1.428降至1.396。这进一步确认了梯度提升树模型在该任务上的适用性。

### 4. XGBoost V2 (Advanced Features)
- **描述**: 此模型基于V2高级特征集（78个特征）进行训练，这些特征包含了更细粒度的表-列使用情况、特定过滤/JOIN模式计数等。
- **特征数量**: 78
- **训练集 MSLE**: 0.385781
- **本地验证集 MSLE**: 0.774980
- **训练时间**: 1.31 秒
- **最佳迭代**: 306
- **观察**: V2特征工程带来了巨大的性能飞跃，本地验证MSLE从1.396大幅降低到0.775。这清晰地证明了详细的、基于数据分析的特征工程的价值。

### 5. XGBoost V3 (Robust Features)
- **描述**: 在V2特征基础上增加了8个旨在提升模型对复杂查询鲁棒性的特征（共86个特征），并对XGBoost超参数进行了微调。
- **特征数量**: 86
- **训练集 MSLE**: 0.398373
- **本地验证集 MSLE**: 0.766269
- **训练时间**: 2.17 秒
- **最佳迭代**: 472
- **观察**: V3特征集在V2的基础上进一步小幅提升了本地验证性能，MSLE从0.775降至0.766。这表明新增的鲁棒性特征对模型泛化能力有积极作用。

## 最终结论与特征影响分析

**最佳本地验证模型**: **XGBoost V3 (Robust Features)** 凭借 **本地验证集 MSLE: 0.766269** 被选为在本地表现最佳的模型。

与基线模型 (训练集 MSLE: 2.410165) 相比，最佳本地验证模型性能提升了约 **68.21%**，展现了机器学习在此任务上的巨大优势。

### 特征工程的核心作用:
特征工程是本项目成功的关键驱动因素，XGBoost系列模型的演进清晰地展示了这一点：
- **XGBoost V1 (Basic Features, 36特征)**: 本地验证集 MSLE = 1.396434
- **XGBoost V2 (Advanced Features, 78特征)**: 本地验证集 MSLE = 0.774980
- **XGBoost V3 (Robust Features, 86特征)**: 本地验证集 MSLE = 0.766269

**分析**: 
  - 从 **V1 到 V2** (引入细粒度表使用、列使用及JOIN项使用情况等特征): 本地验证MSLE实现了 **44.50%** 的显著改进。这突出表明，超越简单计数和原始计划特征，深入挖掘查询结构和具体模式（特别是各个表、列、JOIN项的使用情况）是提升性能的核心。
  - 从 **V2 到 V3** (引入复杂度标记、比率和特定列过滤等鲁棒性特征): 本地验证MSLE实现了 **1.12%** 的进一步改进。虽然幅度较小，但这表明针对性地解决训练/测试集差异、增强模型对未见查询模式的适应性，依然可以带来边际效益。**然而，根据实际竞赛服务器的反馈，从V2到V3的这些鲁棒性特征并未带来实际的性能提升，V3与V2在服务器上的表现相当。** 这提示新增的V3特征可能对本地验证集过拟合，或者竞赛服务器的测试集与本地测试集在这些特定复杂度维度上的差异不如预期那样能被V3特征捕捉并泛化。
  - **总体而言，从V1到V2的特征工程（尤其是表/列/JOIN使用特征的加入）是本次实验中最为关键和有效的性能提升点**。

## 项目关键学习点
- **系统化特征工程**: 迭代式地分析数据、提出特征假设、实现并评估特征是提升模型性能的有效路径。
- **数据一致性检查**: `9_analyze_table_column_usage.py`确认了训练集和测试集在核心结构元素上的一致性，这是构建共享特征映射的基础，避免了因测试集出现全新表/列而导致的特征失配问题。
- **MSLE指标的适用性**: 对于数值范围波动巨大的回归目标（如行数），MSLE是比MSE更合适的评估指标。
- **处理数据差异**: 注意到训练集和（本地）测试集在查询复杂度上的差异，并针对性地设计鲁棒性特征（如V3中的特征），是提升模型泛化能力的一个重要策略。然而，必须通过在真实的、不可见的测试集（如竞赛服务器）上的评估来最终验证这些特征的有效性，以避免对本地验证集的过拟合。

**最终提交选择**: 尽管XGBoost V3在本地验证中略优，但考虑到其在竞赛服务器上并未优于V2，且V2模型更简洁，**因此基于竞赛服务器反馈，XGBoost V2的模型和特征集可能是更稳健的选择。** 本报告记录的最终提交文件 `data/predictions.csv` 是基于XGBoost V3的预测结果生成的（因为这是本地验证最佳），但实际比赛中应权衡服务器反馈。

## 致谢
感谢 Claude 和 Gemini 在项目过程中提供的诸多思路和帮助。 